,pytorch,hex,aims_category,docs,description
0,AdaptiveAvgPool1d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool1d,Applies a 1D adaptive average pooling over an input signal composed of several input planes. The output size is L_{out} for any input size. The number of output features is equal to the number of input planes.
1,AdaptiveAvgPool2d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d,"Applies a 2D adaptive average pooling over an input signal composed of several input planes. The output is of size H x W, for any input size. The number of output features is equal to the number of input planes."
2,AdaptiveAvgPool3d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool3d,"Applies a 3D adaptive average pooling over an input signal composed of several input planes. The output is of size D x H x W, for any input size. The number of output features is equal to the number of input planes."
3,AdaptiveMaxPool1d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool1d,Applies a 1D adaptive max pooling over an input signal composed of several input planes. The output size is L_{out} for any input size. The number of output features is equal to the number of input planes.
4,AdaptiveMaxPool2d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d,"Applies a 2D adaptive max pooling over an input signal composed of several input planes. The output is of size H x W, for any input size. The number of output features is equal to the number of input planes."
5,AdaptiveMaxPool3d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool3d,"Applies a 3D adaptive max pooling over an input signal composed of several input planes. The output is of size D x H x W, for any input size. The number of output features is equal to the number of input planes."
6,AlphaDropout,#cbd5e8,Regularization,https://pytorch.org/docs/stable/generated/torch.nn.AlphaDropout,"Applies Alpha Dropout over the input. Alpha Dropout is a type of Dropout that maintains the self-normalizing property. For an input with zero mean and unit standard deviation, the output of Alpha Dropout maintains the original mean and standard deviation of the input. Alpha Dropout goes hand-in-hand with SELU activation function, which ensures that the outputs have zero mean and unit standard deviation. During training, it randomly masks some of the elements of the input tensor with probability p using samples from a bernoulli distribution. The elements to masked are randomized on every forward call, and scaled and shifted to maintain zero mean and unit standard deviation. During evaluation the module simply computes an identity function."
7,AvgPool1d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AvgPool1d,Applies a 1D average pooling over an input signal composed of several input planes.
8,AvgPool2d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d,Applies a 2D average pooling over an input signal composed of several input planes.
9,AvgPool3d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.AvgPool3d,Applies a 3D average pooling over an input signal composed of several input planes.
10,BatchNorm1d,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d,Applies Batch Normalization over a 2D or 3D input as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
11,BatchNorm2d,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d,Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
12,BatchNorm3d,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d,Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
13,Bilinear,None,Preprocessing,https://pytorch.org/docs/stable/generated/torch.nn.Bilinear,Applies a bilinear transformation to the incoming data.
14,ConstantPad1d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad1d,Pads the input tensor boundaries with a constant value.
15,ConstantPad2d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad2d,Pads the input tensor boundaries with a constant value.
16,ConstantPad3d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad3d,Pads the input tensor boundaries with a constant value.
17,Container,None,None,https://pytorch.org/docs/stable/nn.html#containers,
18,Conv1d,#fdcdac,Convolution,https://pytorch.org/docs/stable/generated/torch.nn.Conv1d,Applies a 1D convolution over an input signal composed of several input planes.
19,Conv2d,#fdcdac,Convolution,https://pytorch.org/docs/stable/generated/torch.nn.Conv2d,Applies a 2D convolution over an input signal composed of several input planes.
20,Conv3d,#fdcdac,Convolution,https://pytorch.org/docs/stable/generated/torch.nn.Conv3d,Applies a 3D convolution over an input signal composed of several input planes.
21,ConvTranspose1d,#fdcdac,Convolution,https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d,"Applies a 1D transposed convolution operator over an input image composed of several input planes. This module can be seen as the gradient of Conv1d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation as it does not compute a true inverse of convolution). For more information, see the visualizations here and the Deconvolutional Networks paper."
22,ConvTranspose2d,#fdcdac,Convolution,https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d,"Applies a 2D transposed convolution operator over an input image composed of several input planes. This module can be seen as the gradient of Conv2d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation as it does not compute a true inverse of convolution). For more information, see the visualizations here and the Deconvolutional Networks paper."
23,ConvTranspose3d,#fdcdac,Convolution,https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d,"Applies a 3D transposed convolution operator over an input image composed of several input planes. The transposed convolution operator multiplies each input value element-wise by a learnable kernel, and sums over the outputs from all input feature planes. This module can be seen as the gradient of Conv3d with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation as it does not compute a true inverse of convolution). For more information, see the visualizations here and the Deconvolutional Networks paper."
24,CosineSimilarity,None,None,https://pytorch.org/docs/stable/generated/torch.nn.functional.cosine_similarity,"Returns cosine similarity between x1 and x2, computed along dim."
25,CrossMapLRN2d,#b3e2cd,Normalization,https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_cross_map_l_r_n2d,A ModuleHolder subclass for CrossMapLRN2dImpl.
26,DataParallel,None,None,https://pytorch.org/docs/stable/generated/torch.nn.DataParallel,"Implements data parallelism at the module level. This container parallelizes the application of the given module by splitting the input across the specified devices by chunking in the batch dimension (other objects will be copied once per device). In the forward pass, the module is replicated on each device, and each replica handles a portion of the input. During the backwards pass, gradients from each replica are summed into the original module. The batch size should be larger than the number of GPUs used."
27,Dropout,#cbd5e8,Regularization,https://pytorch.org/docs/stable/generated/torch.nn.Dropout,"During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call. This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons as described in the paper Improving neural networks by preventing co-adaptation of feature detectors ."
28,Dropout2d,#cbd5e8,Regularization,https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d,"Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj-th channel of the ii-th sample in the batched input is a 2D tensor \text{input}[i, j]input[i,j]). Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution. Usually the input comes from nn.Conv2d modules. As described in the paper Efficient Object Localization Using Convolutional Networks , if adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then i.i.d. dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease."
29,Dropout3d,#cbd5e8,Regularization,https://pytorch.org/docs/stable/generated/torch.nn.Dropout3d,"Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jj-th channel of the ii-th sample in the batched input is a 3D tensor \text{input}[i, j]input[i,j]). Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution. Usually the input comes from nn.Conv3d modules. As described in the paper Efficient Object Localization Using Convolutional Networks , if adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then i.i.d. dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease."
30,Embedding,None,Embedding,https://pytorch.org/docs/stable/generated/torch.nn.Embedding,"A simple lookup table that stores embeddings of a fixed dictionary and size. This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings."
31,EmbeddingBag,None,Embedding,https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag,"Computes sums or means of ‘bags’ of embeddings, without instantiating the intermediate embeddings."
32,FeatureAlphaDropout,#cbd5e8,Regularization,https://pytorch.org/docs/stable/generated/torch.nn.FeatureAlphaDropout,"Randomly masks out entire channels (a channel is a feature map, e.g. the j-th channel of the i-th sample in the batch input is a tensor \text{input}[i, j]input[i,j]) of the input tensor). Instead of setting activations to zero, as in regular Dropout, the activations are set to the negative saturation value of the SELU activation function. Each element will be masked independently for each sample on every forward call with probability p using samples from a Bernoulli distribution. The elements to be masked are randomized on every forward call, and scaled and shifted to maintain zero mean and unit variance."
33,Flatten,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.flatten,"Flattens input by reshaping it into a one-dimensional tensor. If start_dim or end_dim are passed, only dimensions starting with start_dim and ending with end_dim are flattened. The order of elements in input is unchanged."
34,Fold,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.Fold,Combines an array of sliding local blocks into a large containing tensor.
35,FractionalMaxPool2d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool2d,Applies a 2D fractional max pooling over an input signal composed of several input planes. Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham. The max-pooling operation is applied in kH \times kWkH×kW regions by a stochastic step size determined by the target output size. The number of output features is equal to the number of input planes.
36,FractionalMaxPool3d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool3d,Applies a 3D fractional max pooling over an input signal composed of several input planes. Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham. The max-pooling operation is applied in kT \times kH \times kWkT×kH×kW regions by a stochastic step size determined by the target output size. The number of output features is equal to the number of input planes.
37,GRU,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.GRU,Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.
38,GRUCell,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.GRUCell,A gated recurrent unit (GRU) cell.
39,GroupNorm,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm,Applies Group Normalization over a mini-batch of inputs.
40,Identity,None,None,https://pytorch.org/docs/stable/generated/torch.nn.Identity,A placeholder identity operator that is argument-insensitive.
41,InstanceNorm1d,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d,"Applies Instance Normalization over a 2D (unbatched) or 3D (batched) input as described in the paper ""Instance Normalization: The Missing Ingredient for Fast Stylization""."
42,InstanceNorm2d,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d,Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.
43,InstanceNorm3d,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d,Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.
44,LPPool1d,#e6f5c9,Pooling,None,
45,LPPool2d,#e6f5c9,Pooling,None,
46,LSTM,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.LSTM,Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.
47,LSTMCell,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell,A long short-term memory (LSTM) cell.
48,LayerNorm,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm,Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization (https://arxiv.org/abs/1607.06450).
49,Linear,#fff2ae,Dense Layer,https://pytorch.org/docs/stable/generated/torch.nn.Linear,Applies a linear transformation to the incoming data: y = xA^T + b
50,LocalResponseNorm,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm,"Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension. Applies normalization across channels."
51,MaxPool1d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d,Applies a 1D max pooling over an input signal composed of several input planes.
52,MaxPool2d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d,Applies a 2D max pooling over an input signal composed of several input planes.
53,MaxPool3d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d,Applies a 3D max pooling over an input signal composed of several input planes.
54,MaxUnpool1d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d,"Computes a partial inverse of MaxPool1d. MaxPool1d is not fully invertible, since the non-maximal values are lost. MaxUnpool1d takes in as input the output of MaxPool1d including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero."
55,MaxUnpool2d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d,"Computes a partial inverse of MaxPool2d. MaxPool2d is not fully invertible, since the non-maximal values are lost. MaxUnpool2d takes in as input the output of MaxPool2d including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero."
56,MaxUnpool3d,#e6f5c9,Pooling,https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d,"Computes a partial inverse of MaxPool3d. MaxPool3d is not fully invertible, since the non-maximal values are lost. MaxUnpool3d takes in as input the output of MaxPool3d including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero."
57,Module,None,None,https://pytorch.org/docs/stable/generated/torch.nn.Module,"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes."
58,ModuleDict,None,None,https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict,"Holds submodules in a dictionary. ModuleDict can be indexed like a regular Python dictionary, but modules it contains are properly registered, and will be visible by all Module methods."
59,ModuleList,None,None,https://pytorch.org/docs/stable/generated/torch.nn.ModuleList,"Holds submodules in a list. ModuleList can be indexed like a regular Python list, but modules it contains are properly registered, and will be visible by all Module methods."
60,PairwiseDistance,None,None,https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance,Computes the pairwise distance between two vectors using the p-norm
61,Parameter,None,None,https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter,"A kind of Tensor that is to be considered a module parameter. Parameters are Tensor subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in parameters() iterator. Assigning a Tensor doesn’t have such effect. This is because one might want to cache some temporary state, like last hidden state of the RNN, in the model. If there was no such class as Parameter, these temporaries would get registered too."
62,ParameterDict,None,None,https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict,"Holds parameters in a dictionary. ParameterDict can be indexed like a regular Python dictionary, but Parameters it contains are properly registered, and will be visible by all Module methods. Other objects are treated as would be done by a regular Python dictionary. ParameterDict is an ordered dictionary. update() with other unordered mapping types (e.g., Python’s plain dict) does not preserve the order of the merged mapping. On the other hand, OrderedDict or another ParameterDict will preserve their ordering."
63,ParameterList,None,None,https://pytorch.org/docs/stable/generated/torch.nn.ParameterList,"Holds parameters in a list. ParameterList can be used like a regular Python list, but Tensors that are Parameter are properly registered, and will be visible by all Module methods."
64,PixelShuffle,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle,"Rearranges elements in a tensor of shape (*, C \times r^2, H, W) to a tensor of shape (?,C,H×r,W×r), where r is an upscale factor. This is useful for implementing efficient sub-pixel convolution with a stride of 1/r."
65,RNN,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.RNN,Applies a multi-layer Elman RNN with \tanhtanh or \text{ReLU}ReLU non-linearity to an input sequence.
66,RNNBase,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.RNNBase,"Resets parameter data pointer so that they can use faster code paths. Right now, this works only if the module is on the GPU and cuDNN is enabled. Otherwise, it’s a no-op."
67,RNNCell,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.RNNCell,An Elman RNN cell with tanh or ReLU non-linearity.
68,RNNCellBase,#f1e2cc,Sequential,https://pytorch.org/docs/stable/generated/torch.nn.RNNCell,An Elman RNN cell with tanh or ReLU non-linearity.
69,ReflectionPad1d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad1d,Pads the input tensor using the reflection of the input boundary.
70,ReflectionPad2d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad2d,Pads the input tensor using the reflection of the input boundary.
71,ReplicationPad1d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad1d,Pads the input tensor using replication of the input boundary.
72,ReplicationPad2d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad2d,Pads the input tensor using replication of the input boundary.
73,ReplicationPad3d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad3d,Pads the input tensor using replication of the input boundary.
74,Sequential,None,None,https://pytorch.org/docs/stable/generated/torch.nn.Sequential,"A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an OrderedDict of modules can be passed in. The forward() method of Sequential accepts any input and forwards it to the first module it contains. It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module. The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module, such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential)."
75,SyncBatchNorm,#b3e2cd,Normalization,https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm,Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
76,Transformer,#f4cae4,Transformer,https://pytorch.org/docs/stable/generated/torch.nn.Transformer,"A transformer model. User is able to modify the attributes as needed. The architecture is based on the paper “Attention Is All You Need”. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010."
77,TransformerDecoder,#f4cae4,Transformer,https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder,TransformerDecoder is a stack of N decoder layers
78,TransformerDecoderLayer,#f4cae4,Transformer,https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer,"TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network. This standard decoder layer is based on the paper “Attention Is All You Need”. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010."
79,TransformerEncoder,#f4cae4,Transformer,https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder,TransformerEncoder is a stack of N encoder layers
80,TransformerEncoderLayer,#f4cae4,Transformer,https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer,"TransformerEncoderLayer is made up of self-attn and feedforward network. This standard encoder layer is based on the paper “Attention Is All You Need”. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010."
81,Unfold,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.Unfold,Extracts sliding local blocks from a batched input tensor.
82,Upsample,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.Upsample,"Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data. The input data is assumed to be of the form minibatch x channels x [optional depth] x [optional height] x width. Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor. The algorithms available for upsampling are nearest neighbor and linear, bilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor, respectively."
83,UpsamplingBilinear2d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingBilinear2d,Applies a 2D bilinear upsampling to an input signal composed of several input channels.
84,UpsamplingNearest2d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingNearest2d,Applies a 2D nearest neighbor upsampling to an input signal composed of several input channels.
85,ZeroPad2d,#cccccc,Reshaping Layer,https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad2d,Pads the input tensor boundaries with zero.
